{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置中文字体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc(\"font\",family='SimHei') # 中国語フォントの設定\n",
    "plt.rcParams['axes.unicode_minus']=False  # マイナス記号を正常に表示する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')#パソコンにGPUがあるかどうかをチェックする\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像前処理\n",
    "from torchvision import transforms\n",
    "\n",
    "#trainデータセット画像前処理：\n",
    "#1.crop a random portion of image and resize it to a given size\n",
    "#2.horizontally flip the given image randomly with a given probability\n",
    "#3.convert the array into a Tensor\n",
    "#4.the data is transformed to [- 1,1].\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "# validデータセット画像前処理\n",
    "#1.resize the input image to the given size.\n",
    "#2.crops the given image at the center.\n",
    "#3.convert the array into a Tensor\n",
    "#4.the data is transformed to [- 1,1]\n",
    "valid_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットフォルダのパス\n",
    "dataset_dir = 'data_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集路径 data_split/train\n",
      "测试集路径 data_split/val\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "valid_path = os.path.join(dataset_dir, 'val')\n",
    "print('训练集路径', train_path)\n",
    "print('测试集路径', valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "# input trainデータセット\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "\n",
    "# input validデータセット\n",
    "valid_dataset = datasets.ImageFolder(valid_path, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像数量 1008\n",
      "类别个数 4\n",
      "各类别名称 ['其他垃圾', '厨余垃圾', '可回收垃圾', '有害垃圾']\n"
     ]
    }
   ],
   "source": [
    "print('训练集图像数量', len(train_dataset))\n",
    "print('类别个数', len(train_dataset.classes))\n",
    "print('各类别名称', train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集图像数量 251\n",
      "类别个数 4\n",
      "各类别名称 ['其他垃圾', '厨余垃圾', '可回收垃圾', '有害垃圾']\n"
     ]
    }
   ],
   "source": [
    "print('测试集图像数量', len(valid_dataset))\n",
    "print('类别个数', len(valid_dataset.classes))\n",
    "print('各类别名称', valid_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类别和索引号 一一对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各カテゴリーの名称\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['其他垃圾', '厨余垃圾', '可回收垃圾', '有害垃圾']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'其他垃圾': 0, '厨余垃圾': 1, '可回收垃圾': 2, '有害垃圾': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# カテゴリとインデックスのマッピングを作成する\n",
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '其他垃圾', 1: '厨余垃圾', 2: '可回收垃圾', 3: '有害垃圾'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルのnpyファイルとして保存する\n",
    "np.save('idx_to_labels.npy', idx_to_labels)\n",
    "np.save('labels_to_idx.npy', train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据加载器DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# trainデータセット用のデータローダーを作成する\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         )\n",
    "\n",
    "# validデータセット用のデータローダーを作成する\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入训练需使用的工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 只微调训练模型最后一层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/featurize/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5579673c1d924ea7942a2e0942b7a390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True) # resnet18モデルの読み込み，最後のレイヤを微調整する\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# cross-entropy loss function\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "#  Epoch\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [21:51<00:00, 65.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for images, labels in train_loader:  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels) # 現在のバッチの各サンプルについて、 cross-entropy loss functionを計算する\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在测试集上初步测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集上的准确率为 91.633 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#validデータセットで初期テストを行う\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(valid_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum()\n",
    "\n",
    "    print('测试集上的准确率为 {:.3f} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
